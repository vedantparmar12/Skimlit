{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtAgo5zYCClj"
      },
      "source": [
        "# 01. Natural Language Processing with TensorFlow\n",
        "\n",
        "\n",
        "The main goal of [natural language processing (NLP)](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32) is to derive information from natural language.\n",
        "\n",
        "Natural language is a broad term but you can consider it to cover any of the following:\n",
        "* Text (such as that contained in an email, blog post, book, Tweet)\n",
        "* Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## What we're going to cover\n",
        "\n",
        "\n",
        "* Downloading a text dataset\n",
        "* Visualizing text data\n",
        "* Converting text into numbers using tokenization\n",
        "* Turning our tokenized text into an embedding\n",
        "* Modelling a text dataset\n",
        "  * Starting with a baseline (TF-IDF)\n",
        "  * Building several deep learning text models\n",
        "    * Dense, LSTM, GRU, Conv1D, Transfer learning\n",
        "* Comparing the performance of each our models\n",
        "* Combining our models into an ensemble\n",
        "* Saving and loading a trained model\n",
        "* Find the most wrong predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTHLj4iNaAFW",
        "outputId": "60cd2d88-2c91-4e68-c605-f8f47332da96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook last run (end-to-end): 2024-04-30 23:28:27.565630\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEYTFigmc3CI",
        "outputId": "77509eec-0037-4acc-c3e4-887127e974db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-4faf9cc6-3def-440e-8d14-16abc695b339)\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS3YnNNI8oFk"
      },
      "source": [
        "## Get helper functions\n",
        "\n",
        "In past modules, we've created a bunch of helper functions to do small tasks required for our notebooks.\n",
        "\n",
        "Rather than rewrite all of these, we can import a script and load them in from there.\n",
        "\n",
        "The script containing our helper functions can be [found on GitHub](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aFOHPqgE8pv-"
      },
      "outputs": [],
      "source": [
        "### We create a bunch of helpful functions throughout the course.\n",
        "### Storing them here so they're easily accessible.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename (str): string filename of target image\n",
        "  img_shape (int): size to resize target image to, default 224\n",
        "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  if scale:\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img\n",
        "\n",
        "# Note: The following confusion matrix code is a remix of Scikit-Learn's\n",
        "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")\n",
        "\n",
        "# Make a function to predict on images and plot them (works with multi-class)\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n",
        "\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n",
        "\n",
        "def compare_historys(original_history, new_history, initial_epochs=5):\n",
        "    \"\"\"\n",
        "    Compares two TensorFlow model History objects.\n",
        "\n",
        "    Args:\n",
        "      original_history: History object from original model (before new_history)\n",
        "      new_history: History object from continued model training (after original_history)\n",
        "      initial_epochs: Number of epochs in original_history (new_history plot starts from here)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get original history measurements\n",
        "    acc = original_history.history[\"accuracy\"]\n",
        "    loss = original_history.history[\"loss\"]\n",
        "\n",
        "    val_acc = original_history.history[\"val_accuracy\"]\n",
        "    val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine original history with new history\n",
        "    total_acc = acc + new_history.history[\"accuracy\"]\n",
        "    total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n",
        "\n",
        "# Create function to unzip a zipfile into current working directory\n",
        "# (since we're going to be downloading and unzipping a few files)\n",
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Unzips filename into the current working directory.\n",
        "\n",
        "  Args:\n",
        "    filename (str): a filepath to a target zip folder to be unzipped.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "\n",
        "# Walk through an image classification directory and find out how many files (images)\n",
        "# are in each subdirectory.\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "\n",
        "  Args:\n",
        "    dir_path (str): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCZrclc2COWW"
      },
      "source": [
        "## Download a text dataset\n",
        "\n",
        "Let's start by download a text dataset. We'll be using the [Real or Not?](https://www.kaggle.com/c/nlp-getting-started/data) dataset from Kaggle which contains text-based Tweets about natural disasters.\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "The original downloaded data has not been altered to how you would download it from Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0FEcci5IH8S",
        "outputId": "55b59304-bf0a-49ed-e1ce-4bf8b8553244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-30 23:31:42--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.207, 142.251.2.207, 142.250.101.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-30 23:31:42 (102 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBIR6tTI9QcR"
      },
      "source": [
        "Unzipping `nlp_getting_started.zip` gives the following 3 `.csv` files:\n",
        "* `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
        "* `train.csv` - training samples of real and not real diaster Tweets.\n",
        "* `test.csv` - testing samples of real and not real diaster Tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qRvkeYEJIKsw",
        "outputId": "a01c1dcd-aa1d-49f7-b0a8-73d922f40aaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82fcef30-868e-46b4-b009-34483c51f79f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82fcef30-868e-46b4-b009-34483c51f79f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82fcef30-868e-46b4-b009-34483c51f79f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82fcef30-868e-46b4-b009-34483c51f79f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3bf17c0-d462-43da-8f30-863ae8593907\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3bf17c0-d462-43da-8f30-863ae8593907')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3bf17c0-d462-43da-8f30-863ae8593907 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          3796,\n          3185,\n          7769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"Oklahoma\",\n          \"Starling City\",\n          \"Trinidad and Tobago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"Three Homes Demolished in Unrecognized Arab Village - International Middle East Media Center http://t.co/ik8m4Yi9T4\",\n          \"Reid Lake fire prompts campground evacuation order http://t.co/jBODKM6rBU\",\n          \"FAAN orders evacuation of abandoned aircraft at MMA http://t.co/dEvYbnVXGQ via @todayng\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Turn .csv files into pandas DataFrame's\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xGqlnQaLmaT"
      },
      "source": [
        "The training data we downloaded is probably shuffled already. But just to be sure, let's shuffle it again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ACCE7h6OMVjR",
        "outputId": "e46f5dd0-7b70-4a23-e5d7-bf1a6ffc8007"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ecf4752-7fa9-4012-aa41-8210f194652e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ecf4752-7fa9-4012-aa41-8210f194652e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ecf4752-7fa9-4012-aa41-8210f194652e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ecf4752-7fa9-4012-aa41-8210f194652e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c6a57f1-2a8e-4a44-aa6b-3245cb65c857\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c6a57f1-2a8e-4a44-aa6b-3245cb65c857')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c6a57f1-2a8e-4a44-aa6b-3245cb65c857 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df_shuffled",
              "summary": "{\n  \"name\": \"train_df_shuffled\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          7061,\n          843,\n          10603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"blazing\",\n          \"emergency\",\n          \"rescue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"617-BTOWN-BEATDOWN\",\n          \"Newcastle Upon Tyne, England\",\n          \"Federal Capital Territory\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"This week first responders and DART members are participating in a four day intensive Technical Large Animal... http://t.co/tL93AOd3ER\",\n          \"My mom is watching a show about bridges breaking/falling and the people on them drowning in their cars aka one of my biggest fears ????\",\n          \"@NickLee8  i went to school in a bombed out East End of London3 families to one house no bathroom outside loo &amp; poor so whats yr point\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw4mKW1yL0kI"
      },
      "source": [
        "Notice how the training data has a `\"target\"` column.\n",
        "\n",
        "We're going to be writing code to find patterns (e.g. different combinations of words) in the `\"text\"` column of the training dataset to predict the value of the `\"target\"` column.\n",
        "\n",
        "The test dataset doesn't have a `\"target\"` column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tDh5t7thI5BM",
        "outputId": "bc9f2375-0b63-45e1-e4a3-a3f2e82cbb4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa26716c-3be6-4e99-bc9d-3baef5e930ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa26716c-3be6-4e99-bc9d-3baef5e930ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa26716c-3be6-4e99-bc9d-3baef5e930ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa26716c-3be6-4e99-bc9d-3baef5e930ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9623b62-0894-4940-8aa9-14d21aa35451\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9623b62-0894-4940-8aa9-14d21aa35451')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9623b62-0894-4940-8aa9-14d21aa35451 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 3263,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3146,\n        \"min\": 0,\n        \"max\": 10875,\n        \"num_unique_values\": 3263,\n        \"samples\": [\n          8051,\n          425,\n          1330\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1602,\n        \"samples\": [\n          \"UAE\",\n          \"Tokio / Tokyo\",\n          \"Texas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3243,\n        \"samples\": [\n          \"Latest: USA: Huge sinkhole swallows up Brooklyn intersection http://t.co/vspKHg3nZy\",\n          \"I liked a @YouTube video http://t.co/a5YTAw9Vih S.O.S. Rona Guide - The Red Whirlwind\",\n          \"HitchBot travels Europe and greeted with open arms. Gets destroyed after two weeks in america. There's a lesson to be learned here.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# The test data doesn't have a target (that's what we'd try to predict)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4JhBRn5Mn-V"
      },
      "source": [
        "Let's check how many examples of each target we have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4P5DnLhIciD",
        "outputId": "60c9431d-b3a7-48fc-ba8c-708528415515"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0    4342\n",
              "1    3271\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjEDQ297Ihy4"
      },
      "source": [
        "Since we have two target values, we're dealing with a **binary classification** problem.\n",
        "\n",
        "It's fairly balanced too, about 60% negative class (`target = 0`) and 40% positive class (`target = 1`).\n",
        "\n",
        "Where,\n",
        "\n",
        "* `1` = a real disaster Tweet\n",
        "* `0` = not a real disaster Tweet\n",
        "\n",
        "And what about the total number of samples we have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQxg7EKKIy5L",
        "outputId": "0533ec31-48e3-4369-9298-2f1271293d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ]
        }
      ],
      "source": [
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1upY8-xNPWV"
      },
      "source": [
        "Alright, seems like we've got a decent amount of training and test data. If anything, we've got an abundance of testing examples, usually a split of 90/10 (90% training, 10% testing) or 80/20 is suffice.\n",
        "\n",
        "Okay, time to visualize, let's write some code to visualize random text samples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH3EXknTI3bQ",
        "outputId": "455e4926-75e4-4ad5-b175-0b167ae5a9d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Armageddon averted by El Patron\n",
            "#UltimaLucha\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Exploring New Worlds: Three Moments of an Explosion by China MiÌ©ville http://t.co/OTrwZ1t9sp http://t.co/xVlkFCvfX5\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Rocky fire in Northern California swells to 60000 acres; 12000 evacuated http://t.co/mtfnbhRYZq Portland #Phoenix #Miami #Atlanta #Casper\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@DaneMillar1 *screams 666*\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Warne shocked over Australia's epic collapse at Trent Bridge: Johannesburg Aug 06 (ANI): Legendary Australian... http://t.co/LwwoJXtTIV\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FhRRewGPNS_"
      },
      "source": [
        "### Split data into training and validation sets\n",
        "\n",
        "Since the test set has no labels and we need a way to evalaute our trained models, we'll split off some of the training data and create a validation set.\n",
        "\n",
        "When our model trains (tries patterns in the Tweet samples), it'll only see data from the training set and we can see how it performs on unseen data using the validation set.\n",
        "\n",
        "We'll convert our splits from pandas Series datatypes to lists of strings (for the text) and lists of ints (for the labels) for ease of use later.\n",
        "\n",
        "To split our training dataset and create a validation dataset, we'll use Scikit-Learn's [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method and dedicate 10% of the training samples to the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7OJf31TQ-X8s"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42) # random state for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWGOTjanBaTQ",
        "outputId": "3a056e5f-1613-4fc6-a17f-7dd31e300190"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqhvQK9wBTbw",
        "outputId": "e814f419-ebc7-480f-ed71-4c04e9afbf97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object),\n",
              " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN-houoSD-hP"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "\n",
        "\n",
        "Our labels are in numerical form (`0` and `1`) but our Tweets are in string form.\n",
        "\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers:\n",
        "* **Tokenization** - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "  1. Using **word-level tokenization** with the sentence \"I love TensorFlow\" might result in \"I\" being `0`, \"love\" being `1` and \"TensorFlow\" being `2`. In this case, every word in a sequence considered a single **token**.\n",
        "  2. **Character-level tokenization**, such as converting the letters A-Z to values `1-26`. In this case, every character in a sequence considered a single **token**.\n",
        "  3. **Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple **tokens**.\n",
        "* **Embeddings** - An embedding is a representation of natural language which can be learned. Representation comes in the form of a **feature vector**. For example, the word \"dance\" could be represented by the 5-dimensional vector `[-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]`. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "  1. **Create our own embedding** - Once our text has been turned into numbers (required for an embedding), we can put them through an embedding layer (such as [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)) and an embedding representation will be learned during model training.\n",
        "  2. **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UnRcM1PELHn"
      },
      "source": [
        "### Text vectorization (tokenization)\n",
        "\n",
        "Enough talking about tokenization and embeddings, let's create some.\n",
        "\n",
        "We'll practice tokenzation (mapping our words to numbers) first.\n",
        "\n",
        "To tokenize our words, we'll use the helpful preprocessing layer [`tf.keras.layers.experimental.preprocessing.TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization).\n",
        "\n",
        "The `TextVectorization` layer takes the following parameters:\n",
        "* `max_tokens` - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n",
        "* `standardize` - Method for standardizing text. Default is `\"lower_and_strip_punctuation\"` which lowers text and removes all punctuation marks.\n",
        "* `split` - How to split text, default is `\"whitespace\"` which splits on spaces.\n",
        "* `ngrams` - How many words to contain per token split, for example, `ngrams=2` splits tokens into continuous sequences of 2.\n",
        "* `output_mode` -  How to output tokens, can be `\"int\"` (integer mapping), `\"binary\"` (one-hot encoding), `\"count\"` or `\"tf-idf\"`. See documentation for more.\n",
        "* `output_sequence_length` - Length of tokenized sequence to output. For example, if `output_sequence_length=150`, all tokenized sequences will be 150 tokens long.\n",
        "* `pad_to_max_tokens` - Defaults to `False`, if `True`, the output feature axis will be padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than `max_tokens`. Only valid in certain modes, see docs for more.\n",
        "\n",
        "Let's see it in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PVcZk-LcNunF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization # after TensorFlow 2.6\n",
        "\n",
        "# Before TensorFlow 2.6\n",
        "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
        "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
        "\n",
        "# Use the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
        "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Ej5mzKGkK8"
      },
      "source": [
        "We've initialized a `TextVectorization` object with the default settings but let's customize it a little bit for our own use case.\n",
        "\n",
        "In particular, let's set values for `max_tokens` and `output_sequence_length`.\n",
        "\n",
        "For `max_tokens` (the number of words in the vocabulary), multiples of 10,000 (`10,000`, `20,000`, `30,000`) or the exact number of unique words in your text (e.g. `32,179`) are common values.\n",
        "\n",
        "For our use case, we'll use `10,000`.\n",
        "\n",
        "And for the `output_sequence_length` we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ3ZCINnR56H",
        "outputId": "a443b365-5ab9-4254-af2d-ca42ead5d352"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFGTRcw8Hv7R"
      },
      "source": [
        "Now let's create another `TextVectorization` object using our custom parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eYPcGwdbafmW"
      },
      "outputs": [],
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSWycfB3H3wV"
      },
      "source": [
        "To map our `TextVectorization` instance `text_vectorizer` to our data, we can call the `adapt()` method on it whilst passing it our training text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0083KHXPO4m2"
      },
      "outputs": [],
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syh0VB9wIHUq"
      },
      "source": [
        "Training data mapped! Let's try our `text_vectorizer` on a custom sentence (one similar to what you might see in the training data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uizmdJKvO2OW",
        "outputId": "6f527855-a3fd-4ffd-d60a-65afcee9fbe5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0RmAeplIW57"
      },
      "source": [
        "Wonderful, it seems we've got a way to turn our text into numbers (in this case, word-level tokenization). Notice the 0's at the end of the returned tensor, this is because we set `output_sequence_length=15`, meaning no matter the size of the sequence we pass to `text_vectorizer`, it always returns a sequence with a length of 15.\n",
        "\n",
        "How about we try our `text_vectorizer` on a few random sentences?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZFka4BtRR6_",
        "outputId": "115b576c-f053-47b2-8f71-dd3d837eed5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "@LA_Siren Thanks for joining the foot. @VVorm      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   1,  565,   10, 3716,    2, 3837, 6960,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PErGKRbPJF89"
      },
      "source": [
        "we can check the unique tokens in our vocabulary using the `get_vocabulary()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nwNdgAZIhna",
        "outputId": "fd3e8e58-0bf7-48aa-a7f1-310daba1665a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ],
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\")\n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHyCdO0uEOkH"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "\n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather than just being static (e.g. `1` = I, `2` = love, `3` = TensorFlow), a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "* `input_dim` - The size of the vocabulary (e.g. `len(text_vectorizer.get_vocabulary()`).\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of `100` outputs a  feature vector of size 100 for each word.\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is `\"uniform\"` which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "* `input_length` - Length of sequences being passed to embedding layer.\n",
        "\n",
        "Knowing these, let's make an embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsB4StymSk_s",
        "outputId": "c22ecdb0-8af5-49fa-f3ef-56b579d72194"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x7808eb845fc0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\")\n",
        "\n",
        "embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfML_IzlSUho"
      },
      "source": [
        "Excellent, notice how `embedding` is a TensoFlow layer? This is important because we can use it as part of a model, meaning its parameters (word representations) can be updated and improved as the model learns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Re6Eew6SZnG",
        "outputId": "9e6d5c1d-f6e1-48ad-e478-044c180b3f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Maryland mansion fire that killed 6 caused by damaged plug under Christmas tree report says - Into the flames... http://t.co/ucUDwIU3aN      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 1.6084425e-03,  4.1912768e-02, -2.1471882e-02, ...,\n",
              "         -2.5243536e-03, -3.8631260e-06, -2.9487301e-02],\n",
              "        [ 1.8078003e-02,  1.5223656e-02, -3.3829436e-03, ...,\n",
              "         -2.3568107e-02,  2.8246347e-02, -3.7283599e-02],\n",
              "        [ 4.4378582e-02, -3.8148843e-02,  1.3007466e-02, ...,\n",
              "         -3.8423598e-02, -4.5318831e-02,  8.2634464e-03],\n",
              "        ...,\n",
              "        [ 2.5265243e-02, -2.3114085e-02, -1.6448520e-02, ...,\n",
              "         -3.1279765e-02, -1.1906695e-02,  2.4286259e-02],\n",
              "        [ 4.5905355e-02, -2.8394008e-02, -3.2320321e-02, ...,\n",
              "          3.2342557e-02,  4.5224618e-02, -4.2996373e-02],\n",
              "        [ 3.6113229e-02,  3.7493933e-02, -1.5098229e-03, ...,\n",
              "         -2.7854456e-02, -2.9738462e-02, -3.1154348e-02]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Sn8o9pTBE5"
      },
      "source": [
        "Each token in the sentence gets turned into a length 128 feature vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_VBepuSTBDW",
        "outputId": "e604491e-3d52-4311-839b-9fa3ad64ff7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 1.60844252e-03,  4.19127680e-02, -2.14718822e-02,  4.12443168e-02,\n",
              "        4.71856333e-02, -3.76453511e-02, -4.51670066e-02,  1.45447887e-02,\n",
              "       -4.80553173e-02, -3.14194188e-02,  3.03230025e-02, -1.53891072e-02,\n",
              "        8.82804394e-04, -3.71318832e-02, -4.31103371e-02, -4.11014631e-03,\n",
              "       -4.63781953e-02,  1.42317303e-02, -3.86580005e-02, -2.78753396e-02,\n",
              "       -8.40884447e-03,  3.68380658e-02, -3.82612720e-02, -2.74412706e-03,\n",
              "        1.08368769e-02, -2.89695151e-02, -4.52397354e-02,  3.83428670e-02,\n",
              "       -3.90165336e-02, -3.90052572e-02,  3.95316146e-02, -3.32378373e-02,\n",
              "       -4.64625470e-02,  4.54616547e-03,  3.46807390e-03,  6.51769713e-03,\n",
              "       -1.19229928e-02, -2.19399091e-02, -8.43100622e-03,  1.08691677e-02,\n",
              "        1.52129866e-02, -3.30861807e-02,  2.03399770e-02,  4.22571637e-02,\n",
              "       -2.32409593e-02,  3.21697854e-02, -4.57970500e-02,  2.46719271e-03,\n",
              "       -4.19716127e-02,  1.38353221e-02, -1.90191623e-02, -3.31092365e-02,\n",
              "        4.21568789e-02, -5.78405708e-03,  3.50223817e-02,  2.51264684e-02,\n",
              "       -7.97098875e-03,  3.26230787e-02, -7.46177509e-03, -4.55793403e-02,\n",
              "        2.70872228e-02,  8.39729235e-03, -4.67232466e-02, -4.07773964e-02,\n",
              "       -5.48732281e-03, -2.57850178e-02,  4.81668860e-03,  9.71255451e-03,\n",
              "       -4.76130620e-02, -2.99488381e-03, -2.08503008e-02,  4.54355590e-02,\n",
              "        3.81484292e-02, -4.93783019e-02,  4.35439982e-02, -3.80669944e-02,\n",
              "        3.52444500e-03,  3.80910560e-03, -1.65853016e-02,  3.43703516e-02,\n",
              "        1.58155672e-02, -2.29380019e-02, -2.71823294e-02,  1.65367760e-02,\n",
              "        2.19765566e-02,  1.14457384e-02,  1.46927275e-02, -2.49527097e-02,\n",
              "        3.06967162e-02, -2.19934825e-02, -3.99553068e-02, -2.26448178e-02,\n",
              "        1.33931376e-02,  3.81343700e-02, -4.06983867e-02,  1.91160291e-03,\n",
              "       -4.23544645e-02,  1.43135674e-02, -1.89124234e-02, -1.08915456e-02,\n",
              "        1.26732513e-03,  4.07521389e-02,  2.46119238e-02,  3.44691537e-02,\n",
              "        3.44025828e-02, -4.99968417e-02,  3.53760011e-02,  2.87389793e-02,\n",
              "        9.20321792e-03, -3.69619504e-02, -4.37686443e-02,  1.58402659e-02,\n",
              "        1.54484250e-02, -1.34383664e-02,  1.13791935e-02,  2.21677758e-02,\n",
              "       -3.73155251e-02,  1.61247961e-02,  1.18049979e-02, -1.80058852e-02,\n",
              "       -2.29829084e-02,  3.97219546e-02,  3.69140990e-02, -1.51515007e-02,\n",
              "        9.06511396e-03, -2.52435356e-03, -3.86312604e-06, -2.94873007e-02],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJENUdF3F7Rn"
      },
      "source": [
        "## Modelling a text dataset\n",
        "\n",
        "we'll be building the following:\n",
        "* **Model 0**: Naive Bayes (baseline)\n",
        "* **Model 1**: Feed-forward neural network (dense model)\n",
        "* **Model 2**: LSTM model\n",
        "* **Model 3**: GRU model\n",
        "* **Model 4**: Bidirectional-LSTM model\n",
        "* **Model 5**: 1D Convolutional Neural Network\n",
        "* **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
        "* **Model 7**: Same as model 6 with 10% of training data\n",
        "\n",
        "Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "* Construct the model\n",
        "* Train the model\n",
        "* Make predictions with the model\n",
        "* Track prediction evaluation metrics for later comparison\n",
        "\n",
        "Let's get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4i5BiQfF--y"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the [Multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). This was chosen via referring to the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "xFqjqWcXtOOs",
        "outputId": "4eccd56f-541f-481d-e0d2-18633d3134cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybOvOuVJbNjg"
      },
      "source": [
        "The benefit of using a shallow model like Multinomial Naive Bayes is that training is very fast.\n",
        "\n",
        "Let's evaluate our model and find our baseline metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soPfnpmQuUIP",
        "outputId": "04cf0e21-2af5-40db-d0e4-70de955c7fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ],
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUv5dyuibf3M"
      },
      "source": [
        "How about we make some predictions with our baseline model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n89JxrJufcf",
        "outputId": "4f023c35-47ef-4bb4-846c-0e1b8600496f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K354svk_bmdf"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gLmNlDjIxGgJ"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sgy1omMhwr52",
        "outputId": "141150c3-c342-482e-ab62-2a4f5357537b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noRJNm7dGNyh"
      },
      "source": [
        "### Model 1: A simple dense model\n",
        "\n",
        "The first \"deep\" model we're going to build is a single layer dense model. In fact, it's barely going to have a single layer.\n",
        "\n",
        "It'll take our text and labels as input, tokenize the text, create an embedding, find the average of the embedding (using Global Average Pooling) and then pass the average through a fully connected layer with one output unit and a sigmoid activation function.\n",
        "\n",
        "\n",
        "\n",
        "And since we're going to be building a number of TensorFlow deep learning models, we'll import our `create_tensorboard_callback()` function from `helper_functions.py` to keep track of the results of each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PVMPUd3HTit5"
      },
      "outputs": [],
      "source": [
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pib8hHtu7vt1"
      },
      "source": [
        "Now we've got a TensorBoard callback function ready to go, let's build our first deep model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "a_rVtJA7yVBI"
      },
      "outputs": [],
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ubq0ctLD8CQq"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crgltz1O9uku"
      },
      "source": [
        "Model compiled. Let's get a summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkJa-t8aTw1H",
        "outputId": "5243bc85-4cb3-4d5f-ef45-b1b8dfe541fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 128)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1280129 (4.88 MB)\n",
            "Trainable params: 1280129 (4.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get a summary of the model\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH0JLyR09yYt"
      },
      "source": [
        "Most of the trainable parameters are contained within the embedding layer. Recall we created an embedding of size 128 (`output_dim=128`) for a vocabulary of size 10,000 (`input_dim=10000`), hence the 1,280,000 trainable parameters.\n",
        "\n",
        "Alright, our model is compiled, let's fit it to our training data for 5 epochs. We'll also pass our TensorBoard callback function to make sure our model's training metrics are logged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YRYpJIfTvHV",
        "outputId": "55ace58d-fd99-42f4-cfd6-1d57497db488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20240430-234549\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 17s 68ms/step - loss: 0.6100 - accuracy: 0.6911 - val_loss: 0.5363 - val_accuracy: 0.7546\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.4417 - accuracy: 0.8192 - val_loss: 0.4692 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.3468 - accuracy: 0.8606 - val_loss: 0.4590 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2851 - accuracy: 0.8918 - val_loss: 0.4640 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2382 - accuracy: 0.9120 - val_loss: 0.4766 - val_accuracy: 0.7861\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZR5_j9C_LW-"
      },
      "source": [
        "Nice! Since we're using such a simple model, each epoch processes very quickly.\n",
        "\n",
        "Let's check our model's performance on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSTS87YGzuBG",
        "outputId": "1a05e3ea-d573-4092-92ff-cc7ca2520eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4765856862068176, 0.7860892415046692]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M2CTAetBVfW",
        "outputId": "c8a9cb99-fb87-4029-8d95-1c8e1fec94f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
              " array([[-0.06261235,  0.04479365, -0.01942671, ...,  0.03244354,\n",
              "          0.03787545,  0.04266874],\n",
              "        [ 0.03167142,  0.03858844,  0.01648138, ..., -0.00485165,\n",
              "          0.02816375,  0.03217447],\n",
              "        [-0.00889744,  0.0714072 , -0.03050258, ..., -0.03150315,\n",
              "          0.02733545, -0.02446837],\n",
              "        ...,\n",
              "        [-0.04064487,  0.02652148, -0.01520817, ..., -0.00956736,\n",
              "          0.0125117 , -0.04882004],\n",
              "        [-0.02391225,  0.08450831, -0.00952621, ..., -0.03109108,\n",
              "         -0.00666075,  0.06771915],\n",
              "        [-0.11333721,  0.10840459, -0.01966752, ..., -0.04485768,\n",
              "          0.04039136,  0.03244801]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "embedding.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3rfhJFSBrga",
        "outputId": "abd116c1-4fcb-4741-d9a9-f022ad8c1e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ],
      "source": [
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6UrSgRVU6pl"
      },
      "outputs": [],
      "source": [
        "# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
        "# # Upload TensorBoard dev records\n",
        "# !tensorboard dev upload --logdir ./model_logs \\\n",
        "#   --name \"First deep model on text data\" \\\n",
        "#   --description \"Trying a dense model with an embedding layer\" \\\n",
        "#   --one_shot # exits the uploader when upload has finished"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVyJl-VE1ACz"
      },
      "outputs": [],
      "source": [
        "# If you need to remove previous experiments, you can do so using the following command\n",
        "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X7kbEmAzzxM",
        "outputId": "528e7457-1991-4a60-f5f1-24445e4332d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4100298 ],\n",
              "       [0.7443642 ],\n",
              "       [0.9978072 ],\n",
              "       [0.11269005],\n",
              "       [0.10360616],\n",
              "       [0.9305561 ],\n",
              "       [0.9109133 ],\n",
              "       [0.992897  ],\n",
              "       [0.96727455],\n",
              "       [0.2698748 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Make predictions (these come back in the form of probabilities)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWU5e1NLAKJ9"
      },
      "source": [
        "\n",
        "\n",
        "The output threshold of a sigmoid prediction probability doesn't necessarily have to 0.5. For example, through testing, you may find that a cut off of 0.25 is better for your chosen evaluation metrics. A common example of this threshold cutoff is the [precision-recall tradeoff](https://en.wikipedia.org/wiki/Precision_and_recall#Introduction) (search for the keyword \"tradeoff\" to learn about the phenomenon)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf-R_1vsz47P",
        "outputId": "24a2cd19-6277-45ee-8277-5ae202d07c5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
        "model_1_preds[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc3ryY0yCHcI"
      },
      "source": [
        "Now we've got our model's predictions in the form of classes, we can use our `calculate_results()` function to compare them to the ground truth validation labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDEEhYTF0X1y",
        "outputId": "5594af27-36c7-4aa1-dceb-9f46df4030d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.60892388451444,\n",
              " 'precision': 0.7903277546022673,\n",
              " 'recall': 0.7860892388451444,\n",
              " 'f1': 0.7832971347503846}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnkK6Uc7CYlX"
      },
      "source": [
        "How about we compare our first deep model to our baseline model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp88ystW1m0d",
        "outputId": "98c41456-494c-40b1-9686-b338eaa844d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Is our simple Keras model better than our baseline model?\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUINrCdRCpFf"
      },
      "source": [
        "Since we'll be doing this kind of comparison (baseline compared to new model) quite a few times, let's create a function to help us out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo3norTG3GrE",
        "outputId": "63752b07-1973-432d-b3d6-db391515b1a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.61, Difference: -0.66\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
          ]
        }
      ],
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results,\n",
        "                                new_model_results=model_1_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e-1LuioSLAM"
      },
      "source": [
        "## Visualizing learned embeddings\n",
        "\n",
        "Our first model (`model_1`) contained an embedding layer (`embedding`) which learned a way of representing words as feature vectors by passing over the training data.\n",
        "\n",
        "Hearing this for the first few times may sound confusing.\n",
        "\n",
        "So to further help understand what a text embedding is, let's visualize the embedding our model learned.\n",
        "\n",
        "To do so, let's remind ourselves of the words in our vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DkcfRQBVXuJ",
        "outputId": "13f508b6-46e4-47d2-d850-5f5e66b72ffc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzmAPJXQEx6r"
      },
      "source": [
        "And now let's get our embedding layer's weights (these are the numerical representations of each word)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EUR9PwrZphh",
        "outputId": "ab3cc1e6-8b0a-4f57-cbf5-532d93f73a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 128)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1280129 (4.88 MB)\n",
            "Trainable params: 1280129 (4.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xJ5LrInWDLo",
        "outputId": "91f98fc0-50ef-48e4-d55d-cba3b37c85ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ],
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical patterns between the text in the training dataset the model has learned)\n",
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzOJhJHPW1ju"
      },
      "source": [
        "Now we've got these two objects, we can use the [Embedding Projector tool](http://projector.tensorflow.org/_) to visualize our embedding.\n",
        "\n",
        "To use the Embedding Projector tool, we need two files:\n",
        "* The embedding vectors (same as embedding weights).\n",
        "* The meta data of the embedding vectors (the words they represent - our vocabulary).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e9rfcK6WxQE"
      },
      "outputs": [],
      "source": [
        "# # Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "# import io\n",
        "\n",
        "# # Create output writers\n",
        "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# # Write embedding vectors and words to file\n",
        "# for num, word in enumerate(words_in_vocab):\n",
        "#   if num == 0:\n",
        "#      continue # skip padding token\n",
        "#   vec = embed_weights[num]\n",
        "#   out_m.write(word + \"\\n\") # write words to file\n",
        "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "# # Download files locally to upload to Embedding Projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#   pass\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcRdDiEtGQj4"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "For our next series of modelling experiments we're going to be using a special kind of neural network called a **Recurrent Neural Network (RNN)**.\n",
        "\n",
        "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (`X`) and compute an output (`y`) based on all previous inputs.\n",
        "\n",
        "\n",
        "\n",
        "When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence.\n",
        "\n",
        "For a simple example, take two sentences:\n",
        "1. Massive earthquake last week, no?\n",
        "2. No massive earthquake last week.\n",
        "\n",
        "Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n",
        "\n",
        "Recurrent neural networks can be used for a number of sequence-based problems:\n",
        "* **One to one:** one input, one output, such as image classification.\n",
        "* **One to many:** one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "* **Many to one:** many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "* **Many to many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
        "\n",
        "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
        "* Long short-term memory cells (LSTMs).\n",
        "* Gated recurrent units (GRUs).\n",
        "* Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDERKwP_XWro"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "\n",
        "We're going to start with an LSTM-powered RNN.\n",
        "\n",
        "\n",
        "Our model is going to take on a very similar structure to `model_1`:\n",
        "\n",
        "\n",
        "The main difference will be that we're going to add an LSTM layer between our embedding and output.\n",
        "\n",
        "And to make sure we're not getting reusing trained embeddings (this would involve data leakage between models, leading to an uneven comparison later on), we'll create another embedding layer (`model_2_embedding`) for our model. The `text_vectorizer` layer can be reused since it doesn't get updated during training.\n",
        "\n",
        "> 🔑 **Note:** The reason we use a new embedding layer for each model is since the embedding layer is a *learned* representation of words (as numbers), if we were to use the same embedding layer (`embedding_1`) for each model, we'd be mixing what one model learned with the next. And because we want to compare our models later on, starting them with their own embedding layer each time is a better idea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi3vjpFU46hi",
        "outputId": "ba3fad43-1331-48f7-ecc8-04d1df05ef46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ]
        }
      ],
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1wfTARuwWDg"
      },
      "source": [
        "\n",
        "\n",
        "Now we've got our LSTM model built, let's compile it using `\"binary_crossentropy\"` loss and the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "pWdt3bFRwG6w"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2e_t8RFxgXG"
      },
      "source": [
        "And before we fit our model to the data, let's get a summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAjdfDfLwK_R",
        "outputId": "b590752d-a37b-41d3-ce4c-c78f13adad93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1329473 (5.07 MB)\n",
            "Trainable params: 1329473 (5.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5NLw3wD0aMz"
      },
      "source": [
        "Looking good! You'll notice a fair few more trainable parameters within our LSTM layer than `model_1`.\n",
        "\n",
        "\n",
        "\n",
        "Now our first RNN model's compiled let's fit it to our training data, validating it on the validation data and tracking its training parameters using our TensorBoard callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgZ7ojDvwKcq",
        "outputId": "e3cbf47e-a206-4596-f9c4-f5eec3a04a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20240430-235419\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 32ms/step - loss: 0.5116 - accuracy: 0.7402 - val_loss: 0.4548 - val_accuracy: 0.7756\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3168 - accuracy: 0.8716 - val_loss: 0.5123 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.2193 - accuracy: 0.9162 - val_loss: 0.5918 - val_accuracy: 0.7638\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1545 - accuracy: 0.9463 - val_loss: 0.6220 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1101 - accuracy: 0.9602 - val_loss: 0.7855 - val_accuracy: 0.7598\n"
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"LSTM\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gikGe_Z16PP"
      },
      "source": [
        "Nice! We've got our first trained RNN model using LSTM cells. Let's make some predictions with it.\n",
        "\n",
        "The same thing will happen as before, due to the sigmoid activiation function in the final layer, when we call the `predict()` method on our model, it'll return prediction probabilities rather than classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c_lVbKLemrU",
        "outputId": "2a971ff9-db81-43e4-ef77-fb930c14ea65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1),\n",
              " array([[0.0436953 ],\n",
              "        [0.7976073 ],\n",
              "        [0.99856853],\n",
              "        [0.07788213],\n",
              "        [0.00559476],\n",
              "        [0.99869424],\n",
              "        [0.9731496 ],\n",
              "        [0.9995228 ],\n",
              "        [0.99922943],\n",
              "        [0.27669612]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ6ope-ddpOo"
      },
      "source": [
        "We can turn these prediction probabilities into prediction classes by rounding to the nearest integer (by default, prediction probabilities under 0.5 will go to 0 and those over 0.5 will go to 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFnIhtyE7hlb",
        "outputId": "700a59d4-dfbf-462f-cad1-e7bd2a71db51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTBy4poXd_7p"
      },
      "source": [
        "Beautiful, now let's use our `caculate_results()` function to evaluate our LSTM model and our `compare_baseline_to_new_results()` function to compare it to our baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iHXv04y76vj",
        "outputId": "cff62d59-23ac-4acf-f763-3492f45184b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'precision': 0.7599947657549518,\n",
              " 'recall': 0.7598425196850394,\n",
              " 'f1': 0.7584680708642795}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdQGn2L68B5Q",
        "outputId": "85274639-62a9-4288-f035-dbb2a4ed67e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 75.98, Difference: -3.28\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
          ]
        }
      ],
      "source": [
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0pAtADt8ju7"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "\n",
        "To use the GRU cell in TensorFlow, we can call the [`tensorflow.keras.layers.GRU()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) class.\n",
        "\n",
        "The architecture of the GRU-powered model will follow the same structure we've been using:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "\n",
        "Again, the only difference will be the layer(s) we use between the embedding and the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "SoSCGq3H47Yo"
      },
      "outputs": [],
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLT5maFWhKH1"
      },
      "source": [
        "TensorFlow makes it easy to use powerful components such as the GRU cell in our models. And now our third model is built, let's compile it, just as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "lBL1mb31hHDS"
      },
      "outputs": [],
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvnksvkmha2A"
      },
      "source": [
        "What does a summary of our model look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVnB5yQeiAWs",
        "outputId": "3d18af46-e2de-42a2-f483-7d50e0944ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1317313 (5.03 MB)\n",
            "Trainable params: 1317313 (5.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get a summary of the GRU model\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcXzKqgXhdez"
      },
      "source": [
        "Notice the difference in number of trainable parameters between `model_2` (LSTM) and `model_3` (GRU). The difference comes from the LSTM cell having more trainable parameters than the GRU cell.\n",
        "\n",
        "We'll fit our model just as we've been doing previously. We'll also track our models results using our `create_tensorboard_callback()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvamg5JOh_jC",
        "outputId": "9771e616-3007-45ff-aa1e-f8f969648269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20240430-235706\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 13s 49ms/step - loss: 0.5294 - accuracy: 0.7238 - val_loss: 0.4552 - val_accuracy: 0.7782\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.3211 - accuracy: 0.8678 - val_loss: 0.4871 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2204 - accuracy: 0.9159 - val_loss: 0.5536 - val_accuracy: 0.7651\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1586 - accuracy: 0.9453 - val_loss: 0.6148 - val_accuracy: 0.7835\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1201 - accuracy: 0.9594 - val_loss: 0.6172 - val_accuracy: 0.7756\n"
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM4mQj1Sh7Gn"
      },
      "source": [
        "Due to the optimized default settings of the GRU cell in TensorFlow, training doesn't take long at all.\n",
        "\n",
        "Time to make some predictions on the validation samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5TUVHCl9pe-",
        "outputId": "ae0477e1-fa32-486e-c98a-7eebb97ce680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1),\n",
              " array([[0.34902948],\n",
              "        [0.88375044],\n",
              "        [0.9966965 ],\n",
              "        [0.13344474],\n",
              "        [0.01109472],\n",
              "        [0.9914226 ],\n",
              "        [0.6766315 ],\n",
              "        [0.99789727],\n",
              "        [0.99694   ],\n",
              "        [0.62554   ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hasS7dzRiYQh"
      },
      "source": [
        "Again we get an array of prediction probabilities back which we can convert to prediction classes by rounding them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haILbddg98CY",
        "outputId": "b8c538fd-cca7-4f9f-b05a-08ea9f7c4751"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7yAgh-viglB"
      },
      "source": [
        "Now we've got predicted classes, let's evaluate them against the ground truth labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9OZbQu1-LPp",
        "outputId": "c1a015fd-604c-4ee4-8738-6c6e104587de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.55905511811024,\n",
              " 'precision': 0.7755973093483475,\n",
              " 'recall': 0.7755905511811023,\n",
              " 'f1': 0.7746054164754071}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9t7wcALiuRk"
      },
      "source": [
        "Finally we can compare our GRU model's results to our baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7AE6vtn-RQZ",
        "outputId": "bd0623cf-acae-4c57-85da-3de048a1d00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.56, Difference: -1.71\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.01\n"
          ]
        }
      ],
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLm6r4nQ-Wdr"
      },
      "source": [
        "### Model 4: Bidirectonal RNN model\n",
        "\n",
        "Look at us go! We've already built two RNN's with GRU and LSTM cells. Now we're going to look into another kind of RNN, the bidirectional RNN.\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "\n",
        "\n",
        "In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
        "\n",
        "However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "NAU9dvGm47_2"
      },
      "outputs": [],
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hm5cwmNm-g4"
      },
      "source": [
        "> 🔑 **Note:** You can use the `Bidirectional` wrapper on any RNN cell in TensorFlow. For example, `layers.Bidirectional(layers.GRU(64))` creates a bidirectional GRU cell.\n",
        "\n",
        "Our bidirectional model is built, let's compile it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "wP1jeF0am9x0"
      },
      "outputs": [],
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtpYyjsbnEwN"
      },
      "source": [
        "And of course, we'll check out a summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sUd9AQ6nFXI",
        "outputId": "8a0955f1-43db-4491-ef1c-75fbb0ae3489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               98816     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1378945 (5.26 MB)\n",
            "Trainable params: 1378945 (5.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvItfzeZnIE-"
      },
      "source": [
        "Notice the increased number of trainable parameters in `model_4` (bidirectional LSTM) compared to `model_2` (regular LSTM). This is due to the bidirectionality we added to our RNN.\n",
        "\n",
        "Time to fit our bidirectional model and track its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAKY_QbHXPHB",
        "outputId": "a1f417c7-1b60-4b4f-eae3-cbc30338d64c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20240430-235818\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 40ms/step - loss: 0.5079 - accuracy: 0.7478 - val_loss: 0.4596 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.3126 - accuracy: 0.8723 - val_loss: 0.5268 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.2115 - accuracy: 0.9177 - val_loss: 0.5664 - val_accuracy: 0.7559\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.1441 - accuracy: 0.9512 - val_loss: 0.6738 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1030 - accuracy: 0.9623 - val_loss: 0.7236 - val_accuracy: 0.7625\n"
          ]
        }
      ],
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFc7QHRtXmn7",
        "outputId": "3b73b2e3-afac-4191-9ac7-0da9e2441469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01421876],\n",
              "       [0.8469897 ],\n",
              "       [0.99930906],\n",
              "       [0.13661829],\n",
              "       [0.00298985],\n",
              "       [0.99604416],\n",
              "       [0.8937946 ],\n",
              "       [0.99957055],\n",
              "       [0.9994572 ],\n",
              "       [0.27714416]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_9HmNIYobDB"
      },
      "source": [
        "And we'll convert them to prediction classes and evaluate them against the ground truth labels and baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5z8bMdaXw51",
        "outputId": "49cda2c6-a1b9-4d4f-b894-26dbdcb21476"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a7Ym_vKYAO4",
        "outputId": "d96640e1-76ff-4278-c02e-ff1e43aa90d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.24671916010499,\n",
              " 'precision': 0.7625326572242482,\n",
              " 'recall': 0.7624671916010499,\n",
              " 'f1': 0.7612168110136286}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAET-LKpYT18",
        "outputId": "d26026f9-0c66-4045-9fc2-58b54e6062d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.25, Difference: -3.02\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
          ]
        }
      ],
      "source": [
        "# Check to see how the bidirectional model performs against the baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcvt_7emuKlR"
      },
      "source": [
        "## Convolutional Neural Networks for Text\n",
        "\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
        "\n",
        "A typical CNN architecture for sequences will look like the following:\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "The difference again is in the layers component. Instead of using an LSTM or GRU cell, we're going to use a [`tensorflow.keras.layers.Conv1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D) layer followed by a [`tensorflow.keras.layers.GlobablMaxPool1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D) layer.\n",
        "\n",
        "The state that CNNs classify text through the following steps:\n",
        "1. 1-dimensional convolving filters are used as ngram detectors, each filter specializing in a closely-related family of ngrams (an ngram is a collection of n-words, for example, an ngram of 5 might result in \"hello, my name is Daniel\").\n",
        "2. Max-pooling over time extracts the relevant ngrams for making a decision.\n",
        "3. The rest of the network classifies the text based on this information.\n",
        "\n",
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgXEorf9GWY1"
      },
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "Before we build a full 1-dimensional CNN model, let's see a 1-dimensional convolutional layer (also called a **temporal convolution**) in action.\n",
        "\n",
        "We'll first create an embedding of a sample of text and experiment passing it through a `Conv1D()` layer and `GlobalMaxPool1D()` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "563hl7nPWP_3",
        "outputId": "b80402d6-696e-4db3-a5b2-d8654708d5ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WzTeShEemJ2"
      },
      "source": [
        "Notice the output shapes of each layer.\n",
        "\n",
        "The embedding has an output shape dimension of the parameters we set it to (`input_length=15` and `output_dim=128`).\n",
        "\n",
        "The 1-dimensional convolutional layer has an output which has been compressed inline with its parameters. And the same goes for the max pooling layer output.\n",
        "\n",
        "Our text starts out as a string but gets converted to a feature vector of length 64 through various transformation steps (from tokenization to embedding to 1-dimensional convolution to max pool).\n",
        "\n",
        "Let's take a peak at what each of these transformations looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRcxYgs-dxM8",
        "outputId": "eaca0cc1-b6b6-4127-a486-4c1b95b7da7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[ 0.0182307 ,  0.0006638 , -0.01411113, ..., -0.04671139,\n",
              "           0.04754145, -0.00910726],\n",
              "         [-0.02202228,  0.04994492, -0.05394889, ..., -0.04672154,\n",
              "           0.04220126,  0.00113612],\n",
              "         [-0.0443279 ,  0.04316662, -0.03796913, ...,  0.00746332,\n",
              "           0.03628081,  0.03462908],\n",
              "         ...,\n",
              "         [-0.06261235,  0.04479365, -0.01942671, ...,  0.03244354,\n",
              "           0.03787545,  0.04266874],\n",
              "         [-0.06261235,  0.04479365, -0.01942671, ...,  0.03244354,\n",
              "           0.03787545,  0.04266874],\n",
              "         [-0.06261235,  0.04479365, -0.01942671, ...,  0.03244354,\n",
              "           0.03787545,  0.04266874]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[1.41091191e-03, 6.79019094e-02, 0.00000000e+00, 1.11556590e-01,\n",
              "          9.65866297e-02, 1.01773545e-01, 2.50620246e-02, 1.19947828e-02,\n",
              "          0.00000000e+00, 0.00000000e+00, 1.17113721e-02, 0.00000000e+00,\n",
              "          7.41731096e-03, 0.00000000e+00, 8.09522625e-03, 2.42155325e-03,\n",
              "          3.77709279e-03, 4.16272357e-02, 0.00000000e+00, 5.81056997e-02,\n",
              "          0.00000000e+00, 4.45524380e-02, 0.00000000e+00, 8.14158842e-03,\n",
              "          2.96892505e-02, 2.61066575e-03, 4.43423539e-02, 7.40023106e-02,\n",
              "          0.00000000e+00, 1.37210369e-01, 0.00000000e+00, 3.22482479e-03],\n",
              "         [8.03477317e-02, 0.00000000e+00, 9.68877721e-05, 4.60597035e-03,\n",
              "          1.05497360e-01, 1.82539374e-02, 8.27158093e-02, 3.01645473e-02,\n",
              "          3.98900546e-03, 0.00000000e+00, 1.68441534e-02, 0.00000000e+00,\n",
              "          5.63379340e-02, 6.61228001e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "          7.06983507e-02, 6.28955476e-03, 2.13135973e-01, 0.00000000e+00,\n",
              "          3.66847217e-02, 0.00000000e+00, 0.00000000e+00, 4.77462895e-02,\n",
              "          3.75934467e-02, 8.44751745e-02, 1.00132063e-01, 7.24754669e-03,\n",
              "          0.00000000e+00, 5.96052560e-04, 0.00000000e+00, 7.01781362e-02],\n",
              "         [3.41254696e-02, 0.00000000e+00, 0.00000000e+00, 8.17211438e-03,\n",
              "          9.73362625e-02, 9.80757773e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "          0.00000000e+00, 0.00000000e+00, 8.52299184e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 0.00000000e+00, 1.21769207e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 0.00000000e+00, 5.86584508e-02, 1.27071410e-01,\n",
              "          0.00000000e+00, 0.00000000e+00, 1.96347907e-02, 3.38871628e-02,\n",
              "          8.48738700e-02, 6.15365431e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "          0.00000000e+00, 8.47397745e-02, 5.70294671e-02, 0.00000000e+00],\n",
              "         [0.00000000e+00, 0.00000000e+00, 4.36882600e-02, 0.00000000e+00,\n",
              "          1.57636970e-01, 5.97052602e-03, 6.71342760e-02, 0.00000000e+00,\n",
              "          8.69068950e-02, 0.00000000e+00, 2.25122720e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 5.09477966e-02, 3.71001139e-02, 0.00000000e+00,\n",
              "          5.99284321e-02, 0.00000000e+00, 5.02496809e-02, 5.53920791e-02,\n",
              "          0.00000000e+00, 4.31743413e-02, 6.30298303e-03, 7.50301629e-02,\n",
              "          1.79032842e-03, 0.00000000e+00, 0.00000000e+00, 2.41943691e-02,\n",
              "          0.00000000e+00, 9.21475291e-02, 1.88522413e-02, 4.74222824e-02],\n",
              "         [2.15638429e-02, 0.00000000e+00, 2.44730450e-02, 0.00000000e+00,\n",
              "          7.37859309e-02, 1.61134265e-03, 4.37752157e-02, 2.11925060e-03,\n",
              "          0.00000000e+00, 0.00000000e+00, 3.41950506e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "          0.00000000e+00, 0.00000000e+00, 4.47370820e-02, 6.52321149e-03,\n",
              "          0.00000000e+00, 0.00000000e+00, 1.10216122e-02, 7.45100342e-03,\n",
              "          5.15803955e-02, 2.61183754e-02, 1.53005775e-02, 0.00000000e+00,\n",
              "          1.73158310e-02, 3.42156738e-02, 2.93701002e-03, 0.00000000e+00],\n",
              "         [4.43224646e-02, 0.00000000e+00, 4.44240347e-02, 0.00000000e+00,\n",
              "          7.72832632e-02, 2.13382542e-02, 4.09882069e-02, 6.84840605e-04,\n",
              "          0.00000000e+00, 0.00000000e+00, 2.13849880e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 3.36387604e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "          1.16326660e-02, 0.00000000e+00, 6.28370568e-02, 2.20486037e-02,\n",
              "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.32036594e-02,\n",
              "          3.83691639e-02, 1.89295225e-02, 4.32881117e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 2.17290130e-02, 0.00000000e+00, 9.22411680e-03],\n",
              "         [4.43224609e-02, 0.00000000e+00, 4.44240272e-02, 0.00000000e+00,\n",
              "          7.72832632e-02, 2.13382430e-02, 4.09882143e-02, 6.84852013e-04,\n",
              "          0.00000000e+00, 0.00000000e+00, 2.13849824e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 3.36387530e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "          1.16326623e-02, 0.00000000e+00, 6.28370419e-02, 2.20486075e-02,\n",
              "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.32036519e-02,\n",
              "          3.83691564e-02, 1.89295169e-02, 4.32881191e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 2.17290074e-02, 0.00000000e+00, 9.22410749e-03],\n",
              "         [4.43224497e-02, 0.00000000e+00, 4.44240347e-02, 0.00000000e+00,\n",
              "          7.72832483e-02, 2.13382505e-02, 4.09882143e-02, 6.84850616e-04,\n",
              "          0.00000000e+00, 0.00000000e+00, 2.13849880e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 3.36387493e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "          1.16326641e-02, 0.00000000e+00, 6.28370419e-02, 2.20486075e-02,\n",
              "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.32036519e-02,\n",
              "          3.83691639e-02, 1.89295188e-02, 4.32881117e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 2.17290074e-02, 0.00000000e+00, 9.22410004e-03],\n",
              "         [4.43224683e-02, 0.00000000e+00, 4.44240347e-02, 0.00000000e+00,\n",
              "          7.72832632e-02, 2.13382505e-02, 4.09882069e-02, 6.84851431e-04,\n",
              "          0.00000000e+00, 0.00000000e+00, 2.13849843e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 3.36387530e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "          1.16326576e-02, 0.00000000e+00, 6.28370494e-02, 2.20486019e-02,\n",
              "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.32036594e-02,\n",
              "          3.83691639e-02, 1.89295318e-02, 4.32881191e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 2.17290074e-02, 0.00000000e+00, 9.22411494e-03],\n",
              "         [4.43224609e-02, 0.00000000e+00, 4.44240272e-02, 0.00000000e+00,\n",
              "          7.72832558e-02, 2.13382542e-02, 4.09881994e-02, 6.84849336e-04,\n",
              "          0.00000000e+00, 0.00000000e+00, 2.13849768e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 3.36387530e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "          1.16326613e-02, 0.00000000e+00, 6.28370568e-02, 2.20485944e-02,\n",
              "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.32036594e-02,\n",
              "          3.83691564e-02, 1.89295281e-02, 4.32881117e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 2.17290111e-02, 0.00000000e+00, 9.22411680e-03],\n",
              "         [4.43224609e-02, 0.00000000e+00, 4.44240235e-02, 0.00000000e+00,\n",
              "          7.72832632e-02, 2.13382524e-02, 4.09881994e-02, 6.84855215e-04,\n",
              "          0.00000000e+00, 0.00000000e+00, 2.13849880e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 3.36387642e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "          1.16326604e-02, 0.00000000e+00, 6.28370494e-02, 2.20486019e-02,\n",
              "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.32036594e-02,\n",
              "          3.83691564e-02, 1.89295337e-02, 4.32881154e-02, 0.00000000e+00,\n",
              "          0.00000000e+00, 2.17290092e-02, 0.00000000e+00, 9.22411587e-03]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[0.08034773, 0.06790191, 0.04442403, 0.11155659, 0.15763697,\n",
              "         0.10177355, 0.08271581, 0.03016455, 0.0869069 , 0.        ,\n",
              "         0.08522992, 0.        , 0.05633793, 0.0661228 , 0.03710011,\n",
              "         0.00242155, 0.07069835, 0.04162724, 0.21313597, 0.12707141,\n",
              "         0.03668472, 0.04455244, 0.01963479, 0.07503016, 0.08487387,\n",
              "         0.08447517, 0.10013206, 0.07400231, 0.01731583, 0.13721037,\n",
              "         0.05702947, 0.07017814]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# See the outputs of each layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMcrthJwg3B2"
      },
      "source": [
        "Alright, we've seen the outputs of several components of a CNN for sequences, let's put them together and construct a full model, compile it (just as we've done with our other models) and get a summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9aphPWCYkWN",
        "outputId": "24505424-35cc-4f58-bc1b-afc5c30977cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 32)                0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1300545 (4.96 MB)\n",
            "Trainable params: 1300545 (4.96 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "\n",
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our 1D convolution model\n",
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Y4BpMGh0jG"
      },
      "source": [
        "The number of trainable parameters for the 1-dimensional convolutional layer is similar to that of the LSTM layer in `model_2`.\n",
        "\n",
        "Let's fit our 1D CNN model to our text data. In line with previous experiments, we'll save its results using our `create_tensorboard_callback()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fzlaKm1ZrMX",
        "outputId": "39df54a3-8e53-44db-fa03-0c4fb262d4e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20240501-000126\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 41ms/step - loss: 0.5641 - accuracy: 0.7176 - val_loss: 0.4719 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.3408 - accuracy: 0.8616 - val_loss: 0.4692 - val_accuracy: 0.7900\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.2142 - accuracy: 0.9216 - val_loss: 0.5297 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1403 - accuracy: 0.9536 - val_loss: 0.6045 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0973 - accuracy: 0.9670 - val_loss: 0.6588 - val_accuracy: 0.7835\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"Conv1D\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2up-1tLiXKD"
      },
      "source": [
        "Nice! Thanks to GPU acceleration, our 1D convolutional model trains nice and fast. Let's make some predictions with it and evaluate them just as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHYw5GkxZ2OK",
        "outputId": "25f0f639-021c-4386-f8e9-2ca87870b384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18870246],\n",
              "       [0.73853964],\n",
              "       [0.999818  ],\n",
              "       [0.03833732],\n",
              "       [0.00284664],\n",
              "       [0.99509686],\n",
              "       [0.9537875 ],\n",
              "       [0.9980868 ],\n",
              "       [0.99858594],\n",
              "       [0.20349102]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9YqTtjiaauS",
        "outputId": "a6cd4660-63a6-4f36-806c-1459844af30f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMY3s1Pnaj34",
        "outputId": "97c1c262-bc0f-4f2b-cbcd-1053f080fdf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.34645669291339,\n",
              " 'precision': 0.7868445599717488,\n",
              " 'recall': 0.7834645669291339,\n",
              " 'f1': 0.7809185675137833}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# Calculate model_5 evaluation metrics\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRfF4B6_at8k",
        "outputId": "cdaf4a40-97da-43fe-e99f-add9b2845cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.35, Difference: -0.92\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
          ]
        }
      ],
      "source": [
        "# Compare model_5 results to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_roVSSRt-7h"
      },
      "source": [
        "## Using Pretrained Embeddings (transfer learning for NLP)\n",
        "\n",
        "For all of the previous deep learning models we've built and trained, we've created and used our own embeddings from scratch each time.\n",
        "\n",
        "However, a common practice is to leverage pretrained embeddings through **transfer learning**. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "\n",
        "For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-NQ2MA5GZBo"
      },
      "source": [
        "### Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "The main difference between the embedding layer we created and the Universal Sentence Encoder is that rather than create a word-level embedding, the Universal Sentence Encoder, creates a whole sentence-level embedding.\n",
        "\n",
        "Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence.\n",
        "\n",
        "\n",
        "> 🔑 **Note:** An **encoder** is the name for a model which converts raw data such as text into a numerical representation (feature vector), a **decoder** converts the numerical representation to a desired output.\n",
        "\n",
        "As usual, this is best demonstrated with an example.\n",
        "\n",
        "Let's load the Universal Sentence Encoder model and test it on a couple of sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7piW5jtxbUkV",
        "outputId": "d967ed49-7fa0-4f0d-9197-4caa029627e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157028  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680984  0.05589836 -0.0106873  -0.00597291  0.00639323 -0.01819518\n",
            "  0.00030813  0.09105888  0.05874644 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865347 -0.04209306  0.02678981  0.03011006  0.00321069\n",
            " -0.00337973 -0.04787357  0.0226672  -0.00985925 -0.04063613 -0.01292092\n",
            " -0.04666384  0.05630299 -0.03949255  0.00517686  0.02495829 -0.0701444\n",
            "  0.02871508  0.04947684 -0.00633979 -0.08960192  0.02807118 -0.00808364\n",
            " -0.01360602  0.0599865  -0.10361787 -0.05195374  0.00232954 -0.02332531\n",
            " -0.03758105  0.03327728], shape=(50,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When we call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvArnKkGb4vu",
        "outputId": "bd41e386-2ddb-4d58-cde9-b1fc42f3c3ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# Each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "ZcbBj0aXqrs9"
      },
      "outputs": [],
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model\n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvjQl4p7BO_A"
      },
      "source": [
        "Beautiful! Now we've got the USE as a Keras layer, we can use it in a Keras Sequential model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_pjIvPuYltA",
        "outputId": "e1809fba-9653-4f4d-c0fc-7240d267f129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256830721 (979.73 MB)\n",
            "Trainable params: 32897 (128.50 KB)\n",
            "Non-trainable params: 256797824 (979.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yukgxOgCCR2Z"
      },
      "source": [
        "Notice the number of paramters in the USE layer, these are the pretrained weights its learned on various text sources (Wikipedia, web news, web question-answer forums, etc, see the [Universal Sentence Encoder paper](https://www.aclweb.org/anthology/D18-2029.pdf) for more).\n",
        "\n",
        "The trainable parameters are only in our output layers, in other words, we're keeping the USE weights frozen and using it as a feature-extractor. We could fine-tune these weights by setting `trainable=True` when creating the `hub.KerasLayer` instance.\n",
        "\n",
        "Now we've got a feature extractor model ready, let's train it and track its results to TensorBoard using our `create_tensorboard_callback()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX9S0YvafybG",
        "outputId": "57df9993-3cc3-4b6b-e906-db010ef44e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20240501-000448\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 14ms/step - loss: 0.5006 - accuracy: 0.7914 - val_loss: 0.4476 - val_accuracy: 0.7992\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4142 - accuracy: 0.8152 - val_loss: 0.4368 - val_accuracy: 0.8123\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.3996 - accuracy: 0.8219 - val_loss: 0.4329 - val_accuracy: 0.8123\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3924 - accuracy: 0.8269 - val_loss: 0.4284 - val_accuracy: 0.8150\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3862 - accuracy: 0.8291 - val_loss: 0.4299 - val_accuracy: 0.8123\n"
          ]
        }
      ],
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeI0kvVVDmbl"
      },
      "source": [
        "USE model trained! Let's make some predictions with it an evaluate them as we've done with our other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeyNXqU-gM2p",
        "outputId": "7e8c45d1-c35c-4272-d2c0-58139c0dff35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.15870029],\n",
              "       [0.74847883],\n",
              "       [0.9874362 ],\n",
              "       [0.20080213],\n",
              "       [0.72014546],\n",
              "       [0.68733597],\n",
              "       [0.9801869 ],\n",
              "       [0.97552073],\n",
              "       [0.9225749 ],\n",
              "       [0.08774451]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbn1Z0FfgVdx",
        "outputId": "46cd62e7-71d8-433d-d366-5a192f14d306"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2Ow2de3okcb",
        "outputId": "a477da97-6b25-4fa1-a471-7c2fef2cc9ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'precision': 0.8148798668657973,\n",
              " 'recall': 0.8123359580052494,\n",
              " 'f1': 0.810686575717776}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BHnRHHHgp1r",
        "outputId": "cd27adc3-2803-4c14-f6fa-13afae1d2ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 81.23, Difference: 1.97\n",
            "Baseline precision: 0.81, New precision: 0.81, Difference: 0.00\n",
            "Baseline recall: 0.79, New recall: 0.81, Difference: 0.02\n",
            "Baseline f1: 0.79, New f1: 0.81, Difference: 0.02\n"
          ]
        }
      ],
      "source": [
        "# Compare TF Hub model to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHwu4QjijYWG"
      },
      "source": [
        "### Model 7: TensorFlow Hub Pretrained Sentence Encoder 10% of the training data\n",
        "\n",
        "One of the benefits of using transfer learning methods, such as, the pretrained embeddings within the USE is the ability to get great results on a small amount of data (the USE paper even mentions this in the abstract).\n",
        "\n",
        "To put this to the test, we're going to make a small subset of the training data (10%), train a model and evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "W5Sal8DpjzWm"
      },
      "outputs": [],
      "source": [
        "### NOTE: Making splits like this will lead to data leakage ###\n",
        "### (some of the training examples in the validation set) ###\n",
        "\n",
        "### WRONG WAY TO MAKE SPLITS (train_df_shuffled has already been split) ###\n",
        "\n",
        "# # Create subsets of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "XHgowC3GUPJH"
      },
      "outputs": [],
      "source": [
        "# One kind of correct way (there are more) to make data subset\n",
        "# (split the already split train_sentences/train_labels)\n",
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8jaydmiVnJP",
        "outputId": "165d653e-dc25-4ada-b148-40ad129b9e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training examples: 6851\n",
            "Length of 10% training examples: 686\n"
          ]
        }
      ],
      "source": [
        "# Check length of 10 percent datasets\n",
        "print(f\"Total training examples: {len(train_sentences)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E2jr7rSEYT8"
      },
      "source": [
        "Because we've selected a random subset of the training samples, the classes should be roughly balanced (as they are in the full training dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0lEpFT0k0RB",
        "outputId": "e5316915-0289-4174-9181-7af8873355fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    415\n",
              "1    271\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "# Check the number of targets in our subset of data\n",
        "# (this should be close to the distribution of labels in the original train_labels)\n",
        "pd.Series(train_labels_10_percent).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghl1qeGOEnXG"
      },
      "source": [
        "To make sure we're making an appropriate comparison between our model's ability to learn from the full training set and 10% subset, we'll clone our USE model (`model_6`) using the [`tf.keras.models.clone_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model) method.\n",
        "\n",
        "Doing this will create the same architecture but reset the learned weights of the clone target (pretrained weights from the USE will remain but all others will be reset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGmxeAOBjdg2",
        "outputId": "c65103fe-f788-495a-92bc-071384347dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256830721 (979.73 MB)\n",
            "Trainable params: 32897 (128.50 KB)\n",
            "Non-trainable params: 256797824 (979.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Clone model_6 but reset weights\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxFkEM_aFoLK"
      },
      "source": [
        "Notice the layout of `model_7` is the same as `model_6`. Now let's train the newly created model on our 10% training data subset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LklU2maOkgUF",
        "outputId": "b525ebed-f6bf-4afa-ae7c-75050f94b763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20240501-000534\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 46ms/step - loss: 0.6694 - accuracy: 0.6997 - val_loss: 0.6542 - val_accuracy: 0.6929\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6011 - accuracy: 0.7901 - val_loss: 0.5990 - val_accuracy: 0.7323\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.5244 - accuracy: 0.8163 - val_loss: 0.5440 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.4584 - accuracy: 0.8382 - val_loss: 0.5097 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.4137 - accuracy: 0.8397 - val_loss: 0.4918 - val_accuracy: 0.7730\n"
          ]
        }
      ],
      "source": [
        "# Fit the model to 10% of the training data\n",
        "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
        "                              y=train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qpyqdh-F6Eh"
      },
      "source": [
        "Due to the smaller amount of training data, training happens even quicker than before.\n",
        "\n",
        "Let's evaluate our model's performance after learning on 10% of the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot6MRnznlgCL",
        "outputId": "6b02d908-edf1-48ab-9c70-65bf3a4de75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2662866 ],\n",
              "       [0.7724195 ],\n",
              "       [0.89539325],\n",
              "       [0.3216646 ],\n",
              "       [0.57601786],\n",
              "       [0.83050483],\n",
              "       [0.8054859 ],\n",
              "       [0.8416127 ],\n",
              "       [0.83741456],\n",
              "       [0.14180054]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj_4aZellpRu",
        "outputId": "7bcd1ab2-63db-40b4-a1be-701fb4eae605"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_lTXrDblyva",
        "outputId": "2a62db69-3d5b-4347-800e-c1c4feded81e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'precision': 0.777881100544101,\n",
              " 'recall': 0.7729658792650919,\n",
              " 'f1': 0.7695350827050221}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "# Calculate model results\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G84ezltll6DT",
        "outputId": "fccfbe85-28c4-459d-e18a-5d2ae9ff4b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.30, Difference: -1.97\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ],
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_7_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBs9V61EGh0J"
      },
      "source": [
        "## Comparing the performance of each of our models\n",
        "\n",
        "Woah. We've come a long way! From training a baseline to several deep models.\n",
        "\n",
        "Now it's time to compare our model's results.\n",
        "\n",
        "But just before we do, it's worthwhile mentioning, this type of practice is a standard deep learning workflow. Training various different models, then comparing them to see which one performed best and continuing to train it if necessary.\n",
        "\n",
        "The important thing to note is that for all of our modelling experiments we used the same training data (except for `model_7` where we used 10% of the training data).\n",
        "\n",
        "To visualize our model's performances, let's create a pandas DataFrame we our results dictionaries and then plot it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Ex0NSaz7lRf-",
        "outputId": "23d0541b-bb07-46a8-f072-701f9db1851e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 79.265092   0.811139  0.792651  0.786219\n",
              "simple_dense             78.608924   0.790328  0.786089  0.783297\n",
              "lstm                     75.984252   0.759995  0.759843  0.758468\n",
              "gru                      77.559055   0.775597  0.775591  0.774605\n",
              "bidirectional            76.246719   0.762533  0.762467  0.761217\n",
              "conv1d                   78.346457   0.786845  0.783465  0.780919\n",
              "tf_hub_sentence_encoder  81.233596   0.814880  0.812336  0.810687\n",
              "tf_hub_10_percent_data   77.296588   0.777881  0.772966  0.769535"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fe27f91-a946-4578-a965-a145cb301da6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>78.608924</td>\n",
              "      <td>0.790328</td>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.783297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>75.984252</td>\n",
              "      <td>0.759995</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.758468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>77.559055</td>\n",
              "      <td>0.775597</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.774605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>76.246719</td>\n",
              "      <td>0.762533</td>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.761217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>78.346457</td>\n",
              "      <td>0.786845</td>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.780919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>81.233596</td>\n",
              "      <td>0.814880</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.810687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>77.296588</td>\n",
              "      <td>0.777881</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.769535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fe27f91-a946-4578-a965-a145cb301da6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4fe27f91-a946-4578-a965-a145cb301da6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4fe27f91-a946-4578-a965-a145cb301da6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b4b3112-e260-4b81-8398-fc37dbab5d3e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b4b3112-e260-4b81-8398-fc37dbab5d3e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b4b3112-e260-4b81-8398-fc37dbab5d3e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_18511f5d-f678-4b4d-9a1f-9eaff2b7612e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_model_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_18511f5d-f678-4b4d-9a1f-9eaff2b7612e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('all_model_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_model_results",
              "summary": "{\n  \"name\": \"all_model_results\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.704503796305178,\n        \"min\": 75.98425196850394,\n        \"max\": 81.23359580052494,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          78.60892388451444,\n          78.34645669291339,\n          79.26509186351706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02027275832727984,\n        \"min\": 0.7599947657549518,\n        \"max\": 0.8148798668657973,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7903277546022673,\n          0.7868445599717488,\n          0.8111390004213173\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017045037963051787,\n        \"min\": 0.7598425196850394,\n        \"max\": 0.8123359580052494,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7860892388451444,\n          0.7834645669291339,\n          0.7926509186351706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016556307231784275,\n        \"min\": 0.7584680708642795,\n        \"max\": 0.810686575717776,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7832971347503846,\n          0.7809185675137833,\n          0.7862189758049549\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
        "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "v-s2DSLpmM1F"
      },
      "outputs": [],
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "Wp69bR8umD5g",
        "outputId": "30e46422-1948-42a3-aca3-a87677246ebb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avbdkiIuKNNr"
      },
      "source": [
        "Looks like our pretrained USE TensorFlow Hub models have the best performance, even the one with only 10% of the training data seems to outperform the other models. This goes to show the power of transfer learning.\n",
        "\n",
        "How about we drill down and get the F1-score's of each model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "yktdOiufmm3p",
        "outputId": "0b59907a-358a-4b58-deb6-58830dde2749"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv2iE0TPGdNy"
      },
      "source": [
        "Drilling down into a single metric we see our USE TensorFlow Hub models performing  better than all of the other models. Interestingly, the baseline's F1-score isn't too far off the rest of the deeper models.\n",
        "\n",
        "We can also visualize all of our model's training logs using TensorBoard.dev."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "2Ca8TalwGhPf"
      },
      "outputs": [],
      "source": [
        "# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
        "# # Upload TensorBoard dev records\n",
        "# !tensorboard dev upload --logdir ./model_logs \\\n",
        "#   --name \"NLP modelling experiments\" \\\n",
        "#   --description \"A series of different NLP modellings experiments with various models\" \\\n",
        "#   --one_shot # exits the uploader when upload has finished"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os7dv00u21jg"
      },
      "outputs": [],
      "source": [
        "# If you need to remove previous experiments, you can do so using the following command\n",
        "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGVZhTTiGdd5"
      },
      "source": [
        "## Combining our models (model ensembling/stacking)\n",
        "\n",
        "Many production systems use an **ensemble** (multiple different models combined) of models to make a prediction.\n",
        "\n",
        "The idea behind model stacking is that if several uncorrelated models agree on a prediction, then the prediction must be more robust than a prediction made by a singular model.\n",
        "\n",
        "The keyword in the sentence above is **uncorrelated**, which is another way of saying, different types of models. For example, in our case, we might combine our baseline, our bidirectional model and our TensorFlow Hub USE model.\n",
        "\n",
        "Although these models are all trained on the same data, they all have a different way of finding patterns.\n",
        "\n",
        "If we were to use three similarly trained models, such as three LSTM models, the predictions they output will likely be very similar.\n",
        "\n",
        "\n",
        "Since we're working with a classification problem, there are a few of ways we can combine our models:\n",
        "1. **Averaging** - Take the output prediction probabilities of each model for each sample, combine them and then average them.\n",
        "2. **Majority vote (mode)** - Make class predictions with each of your models on all samples, the predicted class is the one in majority. For example, if three different models predict `[1, 0, 1]` respectively, the majority class is `1`, therefore, that would be the predicted label.\n",
        "3. **Model stacking** - Take the outputs of each of your chosen models and use them as inputs to another model.\n",
        "\n",
        "\n",
        "Again, the concept of model stacking is best seen in action.\n",
        "\n",
        "We're going to combine our baseline model (`model_0`), LSTM model (`model_2`) and our USE model trained on the full training data (`model_6`) by averaging the combined prediction probabilities of each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t63u8PCCm-yo",
        "outputId": "6eea4671-8175-4f62-9778-2c196466499f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "# Get mean pred probs for 3 models\n",
        "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
        "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
        "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
        "combined_preds[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abZa7wqlXSI"
      },
      "source": [
        "We've got a combined predictions array of different classes, let's evaluate them against the true labels and add our stacked model's results to our `all_model_results` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieYvhDiev8Et",
        "outputId": "53a4d21b-7092-4454-f698-889b8f0a3ffc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'precision': 0.7805831064048222,\n",
              " 'recall': 0.7808398950131233,\n",
              " 'f1': 0.7806452350205135}"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "# Calculate results from averaging the prediction probabilities\n",
        "ensemble_results = calculate_results(val_labels, combined_preds)\n",
        "ensemble_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "132EHlUUpRrP"
      },
      "outputs": [],
      "source": [
        "# Add our combined model's results to the results DataFrame\n",
        "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "Pm2P1zsvpZ3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d9b894-cdbe-4062-aca8-3c1de988b842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-109-eb0b96b5da6e>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100\n"
          ]
        }
      ],
      "source": [
        "# Convert the accuracy to the same scale as the rest of the results\n",
        "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "trmdZ6eEpwHI",
        "outputId": "86cf7e25-afdf-4463-fb03-dc607231e9ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                  0.792651   0.811139  0.792651  0.786219\n",
              "simple_dense              0.786089   0.790328  0.786089  0.783297\n",
              "lstm                      0.759843   0.759995  0.759843  0.758468\n",
              "gru                       0.775591   0.775597  0.775591  0.774605\n",
              "bidirectional             0.762467   0.762533  0.762467  0.761217\n",
              "conv1d                    0.783465   0.786845  0.783465  0.780919\n",
              "tf_hub_sentence_encoder   0.812336   0.814880  0.812336  0.810687\n",
              "tf_hub_10_percent_data    0.772966   0.777881  0.772966  0.769535\n",
              "ensemble_results         78.083990   0.780583  0.780840  0.780645"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f580317a-9b7e-4096-9693-29d90470bdbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.790328</td>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.783297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.759995</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.758468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.775597</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.774605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.762533</td>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.761217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.786845</td>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.780919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.814880</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.810687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.777881</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.769535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_results</th>\n",
              "      <td>78.083990</td>\n",
              "      <td>0.780583</td>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.780645</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f580317a-9b7e-4096-9693-29d90470bdbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f580317a-9b7e-4096-9693-29d90470bdbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f580317a-9b7e-4096-9693-29d90470bdbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a500184-98eb-41cc-98c8-f96bddbb5393\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a500184-98eb-41cc-98c8-f96bddbb5393')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a500184-98eb-41cc-98c8-f96bddbb5393 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e5fb4578-2451-485b-ab24-71e2de28f05c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_model_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e5fb4578-2451-485b-ab24-71e2de28f05c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('all_model_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_model_results",
              "summary": "{\n  \"name\": \"all_model_results\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.767776148938854,\n        \"min\": 0.7598425196850394,\n        \"max\": 78.08398950131233,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7729658792650919,\n          0.7860892388451444,\n          0.7834645669291339\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019017936267805815,\n        \"min\": 0.7599947657549518,\n        \"max\": 0.8148798668657973,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.777881100544101,\n          0.7903277546022673,\n          0.7868445599717488\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01594426681417988,\n        \"min\": 0.7598425196850394,\n        \"max\": 0.8123359580052494,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7729658792650919,\n          0.7860892388451444,\n          0.7834645669291339\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01550989580816354,\n        \"min\": 0.7584680708642795,\n        \"max\": 0.810686575717776,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7695350827050221,\n          0.7832971347503846,\n          0.7809185675137833\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "all_model_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZwqwF_swdIA"
      },
      "source": [
        "How did the stacked model go against the other models?\n",
        "\n",
        "> 🔑 **Note:** It seems many of our model's results are similar. This may mean there are some limitations to what can be learned from our data. When many of your modelling experiments return similar results, it's a good idea to revisit your data, we'll do this shortly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpwErZOgX_nC"
      },
      "source": [
        "## Saving and loading a trained model\n",
        "\n",
        "Although training time didn't take very long, it's good practice to save your trained models to avoid having to retrain them.\n",
        "\n",
        "Saving your models also enables you to export them for use elsewhere outside of your notebooks, such as in a web application.\n",
        "\n",
        "There are two main ways of [saving a model in TensorFlow](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model):\n",
        "1. The `HDF5` format.\n",
        "2. The `SavedModel` format (default).\n",
        "\n",
        "Let's take a look at both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "SlwjGFVyX-_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e4abc3-ce39-4825-ee71-895e6e56166c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp6zvmprm9A3"
      },
      "source": [
        "If you save a model as a `HDF5`, when loading it back in, you need to let [TensorFlow know about any custom objects you've used](https://www.tensorflow.org/tutorials/keras/save_and_load#saving_custom_objects) (e.g. components which aren't built from pure TensorFlow, such as TensorFlow Hub components)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "sSINZ0Q-nRb2"
      },
      "outputs": [],
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4BCJ8iXnZ4r",
        "outputId": "d425daa1-4bcc-465f-eaf3-24f2c982d227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 11ms/step - loss: 0.4299 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4299291968345642, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02rbT4fwn0It"
      },
      "source": [
        "Calling the `save()` method on our target model and passing it a filepath allows us to save our model in the `SavedModel` format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "e3eVaNBDoMsv"
      },
      "outputs": [],
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-t01S-JoOqK"
      },
      "source": [
        "If you use SavedModel format (default), you can reload your model without specifying custom objects using the [`tensorflow.keras.models.load_model()`](https://www.tensorflow.org/tutorials/keras/save_and_load) function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Dw3zf4fVoU5H"
      },
      "outputs": [],
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqiPr6iiofi1",
        "outputId": "e72646eb-0b9f-43f7-f48b-48ac01a9fbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 18ms/step - loss: 0.4299 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4299292266368866, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "# Evaluate loaded SavedModel format\n",
        "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzp3SHi3oQ3u"
      },
      "source": [
        "If we need a more general-purpose data standard, `HDF5` might be better. For more, check out the [TensorFlow documentation on saving and loading models](https://www.tensorflow.org/tutorials/keras/save_and_load)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5a1648rG3z1"
      },
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "We mentioned before that if many of our modelling experiments are returning similar results, despite using different kinds of models, it's a good idea to return to the data and inspect why this might be.\n",
        "\n",
        "One of the best ways to inspect your data is to sort our model's predictions and find the samples it got *most* wrong, meaning, what predictions had a high prediction probability but turned out to be wrong.\n",
        "\n",
        "Once again, visualization is your friend. Visualize, visualize, visualize.\n",
        "\n",
        "To make things visual, let's take our best performing model's prediction probabilities and classes along with the validation samples (text and ground truth labels) and combine them in a pandas DataFrame.\n",
        "\n",
        "* If our best model still isn't perfect, what examples is it getting wrong?\n",
        "* Which ones are the *most* wrong?\n",
        "* Are there some labels which are wrong? E.g. the model gets it right but the ground truth label doesn't reflect this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gnHfX--TwMIW",
        "outputId": "8c2d0831-016b-4716-db29-b1771b4eb782"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.158700\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.748479\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.987436\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.200802\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.720145"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-874a3266-b609-467a-8859-596bfb5ca52b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.158700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.748479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.987436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.720145</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-874a3266-b609-467a-8859-596bfb5ca52b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-874a3266-b609-467a-8859-596bfb5ca52b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-874a3266-b609-467a-8859-596bfb5ca52b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-54a1ebdd-b933-4b70-b1a4-3c531bae75b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54a1ebdd-b933-4b70-b1a4-3c531bae75b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-54a1ebdd-b933-4b70-b1a4-3c531bae75b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val_df",
              "summary": "{\n  \"name\": \"val_df\",\n  \"rows\": 762,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 761,\n        \"samples\": [\n          \"collapsed the moment i got home last night lol\",\n          \"Reality Training: Train falls off elevated tracks during windstorm http://t.co/qzRciNaF5z\",\n          \"Storm headed towards Idaho Falls with blowing dust &amp; winds to 60 mph.  US HWY 20 &amp; I15 look out.  #idwx http://t.co/0cR74m1Uxm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_prob\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 761,\n        \"samples\": [\n          0.12440399080514908,\n          0.6965945959091187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "# Create dataframe with validation sentences and best performing model predictions\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "val_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKJ9dTbPrIG4"
      },
      "source": [
        "Oh yeah! Now let's find our model's wrong predictions (where `target != pred`) and sort them by their prediction probability (the `pred_prob` column)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "0DwBXQS1wvZx",
        "outputId": "7f71fcd8-bd6e-4155-a4f2-7f1445cd020f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
              "698  åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...       0   1.0   \n",
              "567  @RebeccaforReal accepts Wisconsin Emergency Re...       0   1.0   \n",
              "\n",
              "     pred_prob  \n",
              "31    0.915311  \n",
              "759   0.859078  \n",
              "393   0.857376  \n",
              "628   0.838902  \n",
              "49    0.836873  \n",
              "209   0.819604  \n",
              "251   0.781033  \n",
              "109   0.777842  \n",
              "698   0.773118  \n",
              "567   0.750050  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abd14406-b64e-4b6d-b2f9-59d00dad6696\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.915311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.859078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.857376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.838902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.836873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.819604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.781033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.777842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.773118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>@RebeccaforReal accepts Wisconsin Emergency Re...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.750050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abd14406-b64e-4b6d-b2f9-59d00dad6696')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abd14406-b64e-4b6d-b2f9-59d00dad6696 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abd14406-b64e-4b6d-b2f9-59d00dad6696');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cba5ac34-4ffd-4581-a8c0-1192c9046016\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cba5ac34-4ffd-4581-a8c0-1192c9046016')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cba5ac34-4ffd-4581-a8c0-1192c9046016 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"most_wrong[:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u00e5\\u00c8MGN-AFRICA\\u00e5\\u00a8 pin:263789F4 \\u00e5\\u00c8 Correction: Tent Collapse Story: Correction: Tent Collapse story \\u00e5\\u00c8 http://t.co/fDJUYvZMrv @wizkidayo\",\n          \"FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\",\n          \"Ashes 2015: Australia\\u0089\\u00db\\u00aas collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_prob\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7731177806854248\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3VcRHOusB2D"
      },
      "source": [
        "Finally, we can write some code to visualize the sample text, truth label, prediction class and prediction probability. Because we've sorted our samples by prediction probability, viewing samples from the head of our `most_wrong` DataFrame will show us false positives.\n",
        "\n",
        "A reminder:\n",
        "* `0` = Not a real diaster Tweet\n",
        "* `1` = Real diaster Tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLFYDEsoxRFP",
        "outputId": "fc92b5cc-96b7-4e27-8142-8c3b9a99aa39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.9153106808662415\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8590782880783081\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.857375979423523\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8389020562171936\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8368728160858154\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.819604218006134\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.7810328006744385\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.7778416872024536\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.7731177806854248\n",
            "Text:\n",
            "åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent Collapse Story: Correction: Tent Collapse story åÈ http://t.co/fDJUYvZMrv @wizkidayo\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.7500504851341248\n",
            "Text:\n",
            "@RebeccaforReal accepts Wisconsin Emergency Response Plan on behalf of @GovWalker #nbc15 http://t.co/Pis0aiVRbR\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXCH9J-UspWg"
      },
      "source": [
        "We can view the bottom end of our `most_wrong` DataFrame to inspect false negatives (model predicts 0, not a real diaster Tweet, when it should've predicted 1, real diaster Tweet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EaMchehxwLq",
        "outputId": "0d41e5f8-c17e-4647-d194-58e45319e54e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0, Prob: 0.06137964501976967\n",
            "Text:\n",
            "Next May I'll be free...from school from obligations like family.... Best of all that damn curfew...\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.06114107370376587\n",
            "Text:\n",
            "'The way you move is like a full on rainstorm and I'm a house of cards'\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.05666232481598854\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.05295721814036369\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.051580801606178284\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.043136194348335266\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03919411078095436\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03862462565302849\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03233993798494339\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.031088635325431824\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0W3DWgWJCWs"
      },
      "source": [
        "## Making predictions on the test dataset\n",
        "\n",
        "Alright we've seen how our model's perform on the validation set.\n",
        "\n",
        "But how about the test dataset?\n",
        "\n",
        "We don't have labels for the test dataset so we're going to have to make some predictions and inspect them for ourselves.\n",
        "\n",
        "Let's write some code to make predictions on random samples from the test dataset and visualize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q9lgqoDyequ",
        "outputId": "b68a254d-908b-4a05-cad5-340fcd620a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "Pred: 0, Prob: 0.34616029262542725\n",
            "Text:\n",
            "RT EmekaGift: VPSay NO to President Obama hosting Muhammadu Buhari the #pedophile #terrorist &amp; #mass-murderer\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Pred: 0, Prob: 0.08036500960588455\n",
            "Text:\n",
            "Has the kids' bedtime gotten later &amp; later? Now's a good time to point out to them when their regular curfew would be. #BTSPrep #Parenting\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Pred: 1, Prob: 0.8419773578643799\n",
            "Text:\n",
            "You know it's hot when there are bush fires right near your villa ????\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Pred: 0, Prob: 0.05264878273010254\n",
            "Text:\n",
            "Can you imagine how traumatised Makoto would be if he could see himself in the dub (aka Jersey Shore AU) rn? Well done America\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Pred: 1, Prob: 0.9465028643608093\n",
            "Text:\n",
            "#GRupdates Pic of 16yr old PKK suicide bomber who detonated bomb in Turkey Army trench released --&gt;... http://t.co/P5yASKTq0K\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Pred: 0, Prob: 0.30746549367904663\n",
            "Text:\n",
            "Community first responders #CFR The Radio Ham: Tony Hancock http://t.co/MMSoOOOa70\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Pred: 0, Prob: 0.12896791100502014\n",
            "Text:\n",
            "Why are we not rioting in the streets for change/a future? We outnumber lobbyists! #WakeUpAmerica #CleanPowerPlan http://t.co/sONJy4HK46\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Pred: 1, Prob: 0.5196313858032227\n",
            "Text:\n",
            "@emmap645 @Vickygeex @Zak_Bagans @NickGroff_ @AaronGoodwin A few friends of mine were up investigatin the hellfire last year they had loads\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Pred: 1, Prob: 0.6604959964752197\n",
            "Text:\n",
            "#Fukushima still is not controlled &amp; #seismic retrofitting for other #reactors is a BIG issue @fukushima_actu http://t.co/lCDkTEOukj\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Pred: 1, Prob: 0.7306165099143982\n",
            "Text:\n",
            "'IS Egypt affiliate threatens to kill Croatian hostage in 48 hours' - http://t.co/3LcgidRQpb\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Making predictions on the test dataset\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcvI5zgJ0Tgp"
      },
      "source": [
        "How do our model's predictions look on the test dataset?\n",
        "\n",
        "It's important to do these kind of visualization checks as often as possible to get a glance of how your model performs on unseen data and subsequently how it might perform on the real test: Tweets from the wild."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT1jhk8xdod5"
      },
      "source": [
        "## Predicting on Tweets from the wild\n",
        "\n",
        "How about we find some Tweets and use our model to predict whether or not they're about a diaster or not?\n",
        "\n",
        "To start, let's take one of my own [Tweets on living life like an ensemble model](https://twitter.com/mrdbourke/status/1313649328351662082)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "qHmXxuPH0aUB"
      },
      "outputs": [],
      "source": [
        "# Turn Tweet into string\n",
        "daniels_tweet = \"Life like an ensemble: take the best choices from others and make your own\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPbZaGznvbEx"
      },
      "source": [
        "Now we'll write a small function to take a model and an example sentence and return a prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "KyH9tn9upjld"
      },
      "outputs": [],
      "source": [
        "def predict_on_sentence(model, sentence):\n",
        "  \"\"\"\n",
        "  Uses model to make a prediction on sentence.\n",
        "\n",
        "  Returns the sentence, the predicted label and the prediction probability.\n",
        "  \"\"\"\n",
        "  pred_prob = model.predict([sentence])\n",
        "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
        "  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sentence}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxONpJV8qmWP",
        "outputId": "d094cffa-1ed0-497d-e1c5-318ee7a1d56c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "Pred: 0.0 (not real disaster) Prob: 0.043352674692869186\n",
            "Text:\n",
            "Life like an ensemble: take the best choices from others and make your own\n"
          ]
        }
      ],
      "source": [
        "# Make a prediction on Tweet from the wild\n",
        "predict_on_sentence(model=model_6, # use the USE model\n",
        "                    sentence=daniels_tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYOfNacw08Of"
      },
      "source": [
        " Our model predicted correctly. My Tweet wasn't about a diaster.\n",
        "\n",
        "How about we find a few Tweets about actual diasters?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "AqILBsTK2i9R"
      },
      "outputs": [],
      "source": [
        "# Source - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n",
        "beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
        "\n",
        "# Source - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n",
        "beirut_tweet_2 = \"#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvlbHDISrVmX",
        "outputId": "a236d173-15ce-4676-f97b-23bb7f8cc619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n",
            "Pred: 1.0 (real disaster) Prob: 0.9616581797599792\n",
            "Text:\n",
            "Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"
          ]
        }
      ],
      "source": [
        "# Predict on diaster Tweet 1\n",
        "predict_on_sentence(model=model_6,\n",
        "                    sentence=beirut_tweet_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uKYx11p2zCd",
        "outputId": "9d663cdd-cddb-4855-cc9b-6ef167ec8955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "Pred: 1.0 (real disaster) Prob: 0.9712861180305481\n",
            "Text:\n",
            "#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\n"
          ]
        }
      ],
      "source": [
        "# Predict on diaster Tweet 2\n",
        "predict_on_sentence(model=model_6,\n",
        "                    sentence=beirut_tweet_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fczP1dFcwe98"
      },
      "source": [
        "Looks like our model is performing as expected, predicting both of the diaster Tweets as actual diasters.\n",
        "\n",
        "> 🔑 **Note:** The above examples are cherry-picked and are cases where you'd expect a model to function at high performance. For actual production systems, you'll want to continaully perform tests to see how your model is performing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "DnXp8DKOp3J6"
      },
      "outputs": [],
      "source": [
        "# Calculate the time of predictions\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "\n",
        "  Args:\n",
        "  ----\n",
        "  model = a trained model\n",
        "  sample = a list of samples\n",
        "\n",
        "  Returns:\n",
        "  ----\n",
        "  total_time = total elapsed time for model to make predictions on samples\n",
        "  time_per_pred = time in seconds per single sample\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time-start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(val_sentences) # find prediction time per sample\n",
        "  return total_time, time_per_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxWwS73hze6Z"
      },
      "source": [
        "Looking good!\n",
        "\n",
        "Now let's use our `pred_timer()` function to evaluate the prediction times of our best performing model (`model_6`) and our baseline model (`model_0`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMbGMIWd5c9N",
        "outputId": "7bd57d8f-2e70-4874-fef6-c86a403c3e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2938509499999782, 0.000385631167978974)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "# Calculate TF Hub Sentence Encoder prediction times\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4ej2VyT5oQs",
        "outputId": "98e18d44-8cad-4da7-cdaf-3ea09f17630a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.02078744700020252, 2.7280114173494118e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "# Calculate Naive Bayes prediction times\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "ANKHEfRN7Nhd",
        "outputId": "e0e33cf3-0557-4b81-8776-45c49427956b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-Score\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlHdTqTl0aOq"
      },
      "source": [
        "\n",
        "\n",
        "Of course, the ideal position for each of these dots is to be in the top left of the plot (low time per prediction, high F1-score).\n",
        "\n",
        "In our case, there's a clear tradeoff for time per prediction and performance. Our best performing model takes an order of magnitude longer per prediction but only results in a few F1-score point increase.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}